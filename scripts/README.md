# VB6Parse Documentation Scripts

This directory contains scripts for generating test coverage and performance benchmark data for the VB6Parse documentation site.

## Scripts

### `generate-coverage.sh`
Generates test coverage data and test statistics.

### `generate-benchmarks.sh`
Generates performance benchmark data from Criterion results.

---

## Coverage Generation (`generate-coverage.sh`)

### Usage

```bash
./scripts/generate-coverage.sh
```

### What it does

1. **Generates coverage data** using `cargo llvm-cov` → saves to `docs/coverage.json`
2. **Counts library tests** using `cargo test --lib --list`
3. **Counts doc tests** using `cargo test --doc --list`
4. **Counts integration tests** by iterating through `tests/*.rs` files
5. **Counts fuzz targets** from `fuzz/fuzz_targets/`
6. **Extracts coverage metrics** from the JSON
7. **Creates stats file** → saves to `docs/stats.json`

### Output Files

#### `docs/coverage.json`
Complete coverage data generated by cargo llvm-cov, including per-file coverage details.

#### `docs/stats.json`
Summary statistics loaded dynamically by the website:
```json
{
  "test_count": 5676,
  "lib_tests": 5482,
  "doc_tests": 99,
  "integration_tests": 95,
  "fuzz_targets": 9,
  "line_coverage": 98.51,
  "function_coverage": 93.72,
  "region_coverage": 93.59
}
```

### Dynamic Loading

The website automatically loads `stats.json` via JavaScript in `stats.js`:
- Updates `#test-count-header` element (coverage.html header)
- Updates `.test-count` elements (anywhere test counts appear)
- Updates `.test-count-rounded` elements (rounded to hundreds)
- Updates `[data-stat="key"]` elements with matching stat values

### Adding Dynamic Stats

To display any stat value dynamically in HTML:

```html
<!-- Test count -->
<span class="test-count">5,676</span>

<!-- Rounded test count -->
<span class="test-count-rounded">5,600</span>+

<!-- Individual test categories -->
<div data-stat="lib_tests">5,482</div>
<div data-stat="doc_tests">99</div>
<div data-stat="integration_tests">95</div>
<div data-stat="fuzz_targets">9</div>

<!-- Coverage percentages -->
<div data-stat="line_coverage">98.51</div>
```

The JavaScript will automatically update these with the current values from `stats.json`.

### Requirements

- Rust with cargo
- cargo-llvm-cov (`cargo install cargo-llvm-cov`)
- Python 3

---

## Benchmark Generation (`generate-benchmarks.sh`)

### Usage

```bash
./scripts/generate-benchmarks.sh
```

### What it does

1. **Runs benchmarks** using `cargo bench`
2. **Aggregates results** from `target/criterion/**/new/estimates.json`
3. **Extracts metrics** (mean, median, standard deviation)
4. **Creates benchmark file** → saves to `docs/benchmarks.json`

### Output Files

#### `docs/benchmarks.json`
Aggregated benchmark results from all Criterion benchmarks:
```json
{
  "benchmarks": [
    {
      "name": "bulk_parser_load",
      "mean": 1234567,
      "median": 1234000,
      "std_dev": 12345,
      "unit": "ns"
    }
  ],
  "count": 1
}
```

All timing values are in nanoseconds (ns). The benchmarks.html page automatically converts these to appropriate units (μs, ms, s).

### Viewing Results

Open `docs/benchmarks.html` in a browser or visit the GitHub Pages site. The page displays:
- Summary statistics (total count, average time, fastest/slowest)
- Individual benchmark cards with mean, median, and std dev
- Visual comparison bars
- Search/filter functionality

### Requirements

- Rust with cargo
- Python 3
- Criterion benchmarks configured in `benches/`

---

## CI/CD Integration

These scripts are designed to be run manually or integrated into GitHub Actions workflows:

```yaml
- name: Generate coverage and benchmarks
  run: |
    ./scripts/generate-coverage.sh
    ./scripts/generate-benchmarks.sh
```

The generated JSON files should be committed to the repository so they're available on GitHub Pages.

